{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1396e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 50,\n",
      " 'beam_size': 4,\n",
      " 'checkpoint_save_path': './checkpoint_save',\n",
      " 'dataset_yaml': './examples/pytorch/math_word_problem/mawps/config/new_dynamic_graphsage_undirected.yaml',\n",
      " 'decoder_args': {'rnn_decoder_private': {'max_decoder_step': 35,\n",
      "                                          'max_tree_depth': 8,\n",
      "                                          'use_sibling': False},\n",
      "                  'rnn_decoder_share': {'attention_type': 'uniform',\n",
      "                                        'dropout': 0.3,\n",
      "                                        'fuse_strategy': 'concatenate',\n",
      "                                        'graph_pooling_strategy': None,\n",
      "                                        'hidden_size': 300,\n",
      "                                        'input_size': 300,\n",
      "                                        'rnn_emb_input_size': 300,\n",
      "                                        'rnn_type': 'lstm',\n",
      "                                        'teacher_forcing_rate': 1.0,\n",
      "                                        'use_copy': True,\n",
      "                                        'use_coverage': False}},\n",
      " 'decoder_name': 'stdtree',\n",
      " 'gpuid': -1,\n",
      " 'grad_clip': 5,\n",
      " 'graph_construction_args': {'graph_construction_private': {'as_node': False,\n",
      "                                                            'edge_strategy': 'homogeneous',\n",
      "                                                            'merge_strategy': 'tailhead',\n",
      "                                                            'sequential_link': True},\n",
      "                             'graph_construction_share': {'graph_type': 'dependency',\n",
      "                                                          'port': 9000,\n",
      "                                                          'root_dir': 'examples/pytorch/math_word_problem/mawps/mawps_data',\n",
      "                                                          'share_vocab': True,\n",
      "                                                          'thread_number': 4,\n",
      "                                                          'timeout': 15000,\n",
      "                                                          'topology_subdir': 'dependencygraph'},\n",
      "                             'node_embedding': {'connectivity_ratio': 0.05,\n",
      "                                                'embedding_style': {'bert_lower_case': None,\n",
      "                                                                    'bert_model_name': None,\n",
      "                                                                    'emb_strategy': 'w2v_bilstm',\n",
      "                                                                    'num_rnn_layers': 1,\n",
      "                                                                    'single_token_item': True},\n",
      "                                                'epsilon_neigh': 0.5,\n",
      "                                                'fix_bert_emb': False,\n",
      "                                                'fix_word_emb': False,\n",
      "                                                'hidden_size': 300,\n",
      "                                                'input_size': 300,\n",
      "                                                'num_heads': 1,\n",
      "                                                'rnn_dropout': 0.1,\n",
      "                                                'sim_metric_type': 'weighted_cosine',\n",
      "                                                'smoothness_ratio': 0.1,\n",
      "                                                'sparsity_ratio': 0.1,\n",
      "                                                'top_k_neigh': None,\n",
      "                                                'word_dropout': 0.1}},\n",
      " 'graph_construction_name': 'dependency',\n",
      " 'graph_embedding_args': {'graph_embedding_private': {'activation': 'relu',\n",
      "                                                      'aggregator_type': 'lstm',\n",
      "                                                      'bias': True,\n",
      "                                                      'norm': 'batch_norm',\n",
      "                                                      'use_edge_weight': True},\n",
      "                          'graph_embedding_share': {'attn_drop': 0.0,\n",
      "                                                    'direction_option': 'undirected',\n",
      "                                                    'feat_drop': 0.0,\n",
      "                                                    'hidden_size': 300,\n",
      "                                                    'input_size': 300,\n",
      "                                                    'num_layers': 1,\n",
      "                                                    'output_size': 300}},\n",
      " 'graph_embedding_name': 'graphsage',\n",
      " 'graph_type': 'static',\n",
      " 'init_weight': 0.08,\n",
      " 'learning_rate': 0.001,\n",
      " 'max_epochs': 20,\n",
      " 'min_freq': 1,\n",
      " 'pretrained_word_emb_cache_dir': '.vector_cache',\n",
      " 'pretrained_word_emb_name': None,\n",
      " 'pretrained_word_emb_url': None,\n",
      " 'seed': 123,\n",
      " 'share_vocab': True,\n",
      " 'weight_decay': 0}\n"
     ]
    }
   ],
   "source": [
    "from graph4nlp.pytorch.modules.config import get_basic_args\n",
    "from graph4nlp.pytorch.modules.utils.config_utils import update_values, get_yaml_config\n",
    "\n",
    "def get_args():\n",
    "    config = {'dataset_yaml': \"./examples/pytorch/math_word_problem/mawps/config/new_dynamic_graphsage_undirected.yaml\",\n",
    "              'learning_rate': 1e-3,\n",
    "              'gpuid': -1,\n",
    "              'seed': 123,\n",
    "              'init_weight': 0.08,\n",
    "              'graph_type': 'static',\n",
    "              'weight_decay': 0,\n",
    "              'max_epochs': 20,\n",
    "              'min_freq': 1,\n",
    "              'grad_clip': 5,\n",
    "              'batch_size': 50,\n",
    "              'share_vocab': True,\n",
    "              'pretrained_word_emb_name': None,\n",
    "              'pretrained_word_emb_url': None,\n",
    "              'pretrained_word_emb_cache_dir': \".vector_cache\",\n",
    "              'checkpoint_save_path': \"./checkpoint_save\",\n",
    "              'beam_size': 4\n",
    "              }\n",
    "    our_args = get_yaml_config(config['dataset_yaml'])\n",
    "    template = get_basic_args(graph_construction_name=our_args[\"graph_construction_name\"],\n",
    "                              graph_embedding_name=our_args[\"graph_embedding_name\"],\n",
    "                              decoder_name=our_args[\"decoder_name\"])\n",
    "    update_values(to_args=template, from_args_list=[our_args, config])\n",
    "    return template\n",
    "\n",
    "# show our config\n",
    "cfg_g2t = get_args()\n",
    "from pprint import pprint\n",
    "pprint(cfg_g2t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed1c7a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from graph4nlp.pytorch.data.data import to_batch\n",
    "from graph4nlp.pytorch.datasets.mawps import MawpsDatasetForTree\n",
    "from graph4nlp.pytorch.modules.graph_construction import DependencyBasedGraphConstruction\n",
    "from graph4nlp.pytorch.modules.graph_embedding import *\n",
    "from graph4nlp.pytorch.models.graph2tree import Graph2Tree\n",
    "from graph4nlp.pytorch.modules.utils.tree_utils import Tree #prepare_oov\n",
    "\n",
    "# from utils import convert_to_string, compute_tree_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e02fcf",
   "metadata": {},
   "source": [
    "\n",
    "# implementing runner file inside examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abde98c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "import argparse\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from graph4nlp.pytorch.data.data import to_batch\n",
    "from graph4nlp.pytorch.datasets.mawps import MawpsDatasetForTree\n",
    "from graph4nlp.pytorch.modules.graph_construction import *\n",
    "from graph4nlp.pytorch.modules.graph_embedding import *\n",
    "from graph4nlp.pytorch.models.graph2tree import Graph2Tree\n",
    "from graph4nlp.pytorch.modules.utils.tree_utils import Tree, VocabForAll\n",
    "from examples.pytorch.math_word_problem.mawps.src.evaluation import convert_to_string, compute_tree_accuracy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc1968f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mawps:\n",
    "    def __init__(self, opt=None):\n",
    "        super(Mawps, self).__init__()\n",
    "        self.opt = opt\n",
    "\n",
    "        seed = self.opt[\"seed\"]\n",
    "        print(seed)\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        print(opt[\"gpuid\"])\n",
    "        if self.opt[\"gpuid\"] == -1:\n",
    "            self.device = torch.device(\"cpu\")\n",
    "        else:\n",
    "            self.device = torch.device(\"cuda:{}\".format(self.opt[\"gpuid\"]))\n",
    "\n",
    "        self.use_copy = self.opt[\"decoder_args\"][\"rnn_decoder_share\"][\"use_copy\"]\n",
    "        self.use_share_vocab = self.opt[\"graph_construction_args\"][\"graph_construction_share\"][\"share_vocab\"]\n",
    "        self.data_dir = self.opt[\"graph_construction_args\"][\"graph_construction_share\"][\"root_dir\"]\n",
    "\n",
    "        self._build_dataloader()\n",
    "        self._build_model()\n",
    "        self._build_optimizer()\n",
    "\n",
    "    def _build_dataloader(self):\n",
    "        graph_type = self.opt[\"graph_construction_args\"][\"graph_construction_share\"][\"graph_type\"]\n",
    "        enc_emb_size = self.opt[\"graph_construction_args\"][\"node_embedding\"][\"input_size\"]\n",
    "        tgt_emb_size = self.opt[\"decoder_args\"][\"rnn_decoder_share\"][\"input_size\"]\n",
    "        topology_subdir = self.opt[\"graph_construction_args\"][\"graph_construction_share\"][\"topology_subdir\"]\n",
    "        if graph_type == \"dependency\":\n",
    "            dataset = MawpsDatasetForTree(root_dir=self.data_dir,\n",
    "                                         topology_builder=DependencyBasedGraphConstruction,\n",
    "                                         topology_subdir=topology_subdir, \n",
    "                                         edge_strategy=self.opt[\"graph_construction_args\"][\"graph_construction_private\"][\"edge_strategy\"],\n",
    "                                         graph_type='static',\n",
    "                                         share_vocab=self.use_share_vocab, \n",
    "                                         enc_emb_size=enc_emb_size,\n",
    "                                         dec_emb_size=tgt_emb_size,\n",
    "                                         min_word_vocab_freq=self.opt[\"min_freq\"],\n",
    "                                         pretrained_word_emb_name=self.opt[\"pretrained_word_emb_name\"],\n",
    "                                         pretrained_word_emb_url=self.opt[\"pretrained_word_emb_url\"], \n",
    "                                         pretrained_word_emb_cache_dir=self.opt[\"pretrained_word_emb_cache_dir\"])\n",
    "\n",
    "        elif graph_type == \"constituency\":\n",
    "            dataset = MawpsDatasetForTree(root_dir=self.data_dir,\n",
    "                                         topology_builder=ConstituencyBasedGraphConstruction,\n",
    "                                         topology_subdir=topology_subdir, \n",
    "                                         edge_strategy=self.opt[\"graph_construction_args\"][\"graph_construction_private\"][\"edge_strategy\"],\n",
    "                                         graph_type='static',\n",
    "                                         share_vocab=self.use_share_vocab, \n",
    "                                         enc_emb_size=enc_emb_size,\n",
    "                                         dec_emb_size=tgt_emb_size,\n",
    "                                         min_word_vocab_freq=self.opt[\"min_freq\"],\n",
    "                                         pretrained_word_emb_name=self.opt[\"pretrained_word_emb_name\"],\n",
    "                                         pretrained_word_emb_url=self.opt[\"pretrained_word_emb_url\"], \n",
    "                                         pretrained_word_emb_cache_dir=self.opt[\"pretrained_word_emb_cache_dir\"])\n",
    "                                         \n",
    "        elif graph_type == \"node_emb\":\n",
    "            dataset = MawpsDatasetForTree(root_dir=self.data_dir, \n",
    "                                         word_emb_size=enc_emb_size,\n",
    "                                         topology_builder=NodeEmbeddingBasedGraphConstruction,\n",
    "                                         topology_subdir=topology_subdir, \n",
    "                                         graph_type='dynamic',\n",
    "                                         dynamic_graph_type=graph_type, \n",
    "                                         edge_strategy=self.opt[\"graph_construction_args\"][\"graph_construction_private\"][\"edge_strategy\"],\n",
    "                                         share_vocab=self.use_share_vocab, \n",
    "                                         enc_emb_size=enc_emb_size,\n",
    "                                         dec_emb_size=tgt_emb_size,\n",
    "                                         min_word_vocab_freq=self.opt[\"min_freq\"],\n",
    "                                         pretrained_word_emb_name=self.opt[\"pretrained_word_emb_name\"],\n",
    "                                         pretrained_word_emb_url=self.opt[\"pretrained_word_emb_url\"], \n",
    "                                         pretrained_word_emb_cache_dir=self.opt[\"pretrained_word_emb_cache_dir\"])\n",
    "    \n",
    "        elif graph_type == \"node_emb_refined\":\n",
    "            dynamic_init_graph_type = self.opt[\"graph_construction_args\"][\"graph_construction_private\"][\"dynamic_init_graph_type\"]\n",
    "            if dynamic_init_graph_type is None or dynamic_init_graph_type == 'line':\n",
    "                dynamic_init_topology_builder = None\n",
    "            elif dynamic_init_graph_type == 'dependency':\n",
    "                dynamic_init_topology_builder = DependencyBasedGraphConstruction\n",
    "            elif dynamic_init_graph_type == 'constituency':\n",
    "                dynamic_init_topology_builder = ConstituencyBasedGraphConstruction\n",
    "            else:\n",
    "                # dynamic_init_topology_builder\n",
    "                raise RuntimeError('Define your own dynamic_init_topology_builder')\n",
    "            dataset = MawpsDatasetForTree(root_dir=self.data_dir,\n",
    "                                         word_emb_size=enc_emb_size,\n",
    "                                         topology_builder=NodeEmbeddingBasedRefinedGraphConstruction,\n",
    "                                         topology_subdir=topology_subdir,\n",
    "                                         graph_type='dynamic',\n",
    "                                         dynamic_graph_type=graph_type,\n",
    "                                         share_vocab=self.use_share_vocab,\n",
    "                                         enc_emb_size=enc_emb_size, \n",
    "                                         dec_emb_size=tgt_emb_size,\n",
    "                                         dynamic_init_topology_builder=dynamic_init_topology_builder,\n",
    "                                         min_word_vocab_freq=self.opt[\"min_freq\"],\n",
    "                                         pretrained_word_emb_name=self.opt[\"pretrained_word_emb_name\"],\n",
    "                                         pretrained_word_emb_url=self.opt[\"pretrained_word_emb_url\"], \n",
    "                                         pretrained_word_emb_cache_dir=self.opt[\"pretrained_word_emb_cache_dir\"])                                         \n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        self.train_data_loader = DataLoader(dataset.train, batch_size=self.opt[\"batch_size\"], shuffle=True, num_workers=1,\n",
    "                                           collate_fn=dataset.collate_fn)\n",
    "        self.test_data_loader = DataLoader(dataset.test, batch_size=1, shuffle=False, num_workers=1,\n",
    "                                          collate_fn=dataset.collate_fn)\n",
    "        self.valid_data_loader = DataLoader(dataset.val, batch_size=1, shuffle=False, num_workers=1,\n",
    "                                          collate_fn=dataset.collate_fn)\n",
    "        self.src_vocab = dataset.src_vocab_model\n",
    "        self.tgt_vocab = dataset.tgt_vocab_model\n",
    "        if self.use_share_vocab:\n",
    "            self.share_vocab = dataset.share_vocab_model\n",
    "        self.vocab_model = VocabForAll(in_word_vocab=self.src_vocab, out_word_vocab=self.tgt_vocab, share_vocab=self.share_vocab)\n",
    "\n",
    "    def _build_model(self):\n",
    "        '''For encoder-decoder'''\n",
    "        self.model = Graph2Tree.from_args(self.opt, vocab_model=self.vocab_model)\n",
    "        self.model.init(self.opt[\"init_weight\"])\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def _build_optimizer(self):\n",
    "        optim_state = {\"learningRate\": self.opt[\"learning_rate\"], \"weight_decay\": self.opt[\"weight_decay\"]}\n",
    "        parameters = [p for p in self.model.parameters() if p.requires_grad]\n",
    "        self.optimizer = optim.Adam(parameters, lr=optim_state['learningRate'], weight_decay=optim_state['weight_decay'])\n",
    "\n",
    "    def prepare_ext_vocab(self, batch_graph, src_vocab):\n",
    "        oov_dict = copy.deepcopy(src_vocab)\n",
    "        token_matrix = []\n",
    "        for n in batch_graph.node_attributes:\n",
    "            node_token = n['token']\n",
    "            if (n.get('type') == None or n.get('type') == 0) and oov_dict.get_symbol_idx(node_token) == oov_dict.get_symbol_idx(oov_dict.unk_token):\n",
    "                oov_dict.add_symbol(node_token)\n",
    "            token_matrix.append(oov_dict.get_symbol_idx(node_token))\n",
    "        batch_graph.node_features['token_id_oov'] = torch.tensor(token_matrix, dtype=torch.long).to(self.device)\n",
    "        return oov_dict\n",
    "\n",
    "    def train_epoch(self, epoch):\n",
    "        loss_to_print = 0\n",
    "        num_batch = len(self.train_data_loader)\n",
    "        for step, data in enumerate(self.train_data_loader):\n",
    "            batch_graph, batch_tree_list, batch_original_tree_list = data['graph_data'], data['dec_tree_batch'], data['original_dec_tree_batch']\n",
    "            batch_graph = batch_graph.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            oov_dict = self.prepare_ext_vocab(\n",
    "                batch_graph, self.src_vocab) if self.use_copy else None\n",
    "\n",
    "            if self.use_copy:\n",
    "                batch_tree_list_refined = []\n",
    "                for item in batch_original_tree_list:\n",
    "                    tgt_list = oov_dict.get_symbol_idx_for_list(item.strip().split())\n",
    "                    tgt_tree = Tree.convert_to_tree(tgt_list, 0, len(tgt_list), oov_dict)\n",
    "                    batch_tree_list_refined.append(tgt_tree)\n",
    "            loss = self.model(batch_graph, batch_tree_list_refined if self.use_copy else batch_tree_list, oov_dict=oov_dict)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_value_(\n",
    "                self.model.parameters(), self.opt[\"grad_clip\"])\n",
    "            self.optimizer.step()\n",
    "            loss_to_print += loss\n",
    "        return loss_to_print/num_batch\n",
    "\n",
    "    def train(self):\n",
    "        best_acc = (-1, -1)\n",
    "\n",
    "        print(\"-------------\\nStarting training.\")\n",
    "        for epoch in range(1, self.opt[\"max_epochs\"]+1):\n",
    "            self.model.train()\n",
    "            loss_to_print = self.train_epoch(epoch)\n",
    "            print(\"epochs = {}, train_loss = {:.3f}\".format(epoch, loss_to_print))\n",
    "            if epoch > 2 and epoch % 5 == 0:\n",
    "                test_acc = self.eval(self.model, mode=\"test\")\n",
    "                val_acc = self.eval(self.model, mode=\"val\")\n",
    "                if val_acc > best_acc[1]:\n",
    "                    best_acc = (test_acc, val_acc)\n",
    "        print(\"Best Acc: {:.3f}\\n\".format(best_acc[0]))\n",
    "        return best_acc\n",
    "\n",
    "    def eval(self, model, mode=\"val\"):\n",
    "        \n",
    "        model.eval()\n",
    "        reference_list = []\n",
    "        candidate_list = []\n",
    "        data_loader = self.test_data_loader if mode == \"test\" else self.valid_data_loader\n",
    "        for data in data_loader:\n",
    "            eval_input_graph, batch_tree_list, batch_original_tree_list = data['graph_data'], data['dec_tree_batch'], data['original_dec_tree_batch']\n",
    "            eval_input_graph = eval_input_graph.to(self.device)\n",
    "            oov_dict = self.prepare_ext_vocab(eval_input_graph, self.src_vocab)\n",
    "\n",
    "            if self.use_copy:\n",
    "                assert len(batch_original_tree_list) == 1\n",
    "                reference = oov_dict.get_symbol_idx_for_list(batch_original_tree_list[0].split())\n",
    "                eval_vocab = oov_dict\n",
    "            else:\n",
    "                assert len(batch_original_tree_list) == 1\n",
    "                reference = model.tgt_vocab.get_symbol_idx_for_list(batch_original_tree_list[0].split())\n",
    "                eval_vocab = self.tgt_vocab\n",
    "\n",
    "            candidate = model.decoder.translate(model.use_copy,\n",
    "                                                model.decoder.enc_hidden_size,\n",
    "                                                model.decoder.hidden_size,\n",
    "                                                model,\n",
    "                                                eval_input_graph,\n",
    "                                                self.src_vocab,\n",
    "                                                self.tgt_vocab,\n",
    "                                                self.device,\n",
    "                                                self.opt[\"decoder_args\"][\"rnn_decoder_private\"][\"max_decoder_step\"],\n",
    "                                                self.opt[\"decoder_args\"][\"rnn_decoder_private\"][\"max_tree_depth\"],\n",
    "                                                oov_dict=oov_dict,\n",
    "                                                use_beam_search=True,\n",
    "                                                beam_size=self.opt[\"beam_size\"])\n",
    "            \n",
    "            candidate = [int(c) for c in candidate]\n",
    "            num_left_paren = sum(\n",
    "                1 for c in candidate if eval_vocab.idx2symbol[int(c)] == \"(\")\n",
    "            num_right_paren = sum(\n",
    "                1 for c in candidate if eval_vocab.idx2symbol[int(c)] == \")\")\n",
    "            diff = num_left_paren - num_right_paren\n",
    "            if diff > 0:\n",
    "                for i in range(diff):\n",
    "                    candidate.append(\n",
    "                        self.test_data_loader.tgt_vocab.symbol2idx[\")\"])\n",
    "            elif diff < 0:\n",
    "                candidate = candidate[:diff]\n",
    "            ref_str = convert_to_string(\n",
    "                reference, eval_vocab)\n",
    "            cand_str = convert_to_string(\n",
    "                candidate, eval_vocab)\n",
    "\n",
    "            reference_list.append(reference)\n",
    "            candidate_list.append(candidate)\n",
    "        test_acc = compute_tree_accuracy(\n",
    "            candidate_list, reference_list, eval_vocab)\n",
    "        print(\"TEST ACCURACY = {:.3f}\\n\".format(test_acc))\n",
    "        return test_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fdcca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "#     from examples.pytorch.math_word_problem.mawps.src.config import get_args\n",
    "    start = time.time()\n",
    "    runner = Mawps(opt=get_args())\n",
    "    best_acc = runner.train()\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"total time: {} minutes\\n\".format((end - start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19d9718b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/vaishnavipariti/Documents/sem5_project/graph4nlp'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecfef089",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (288393570.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[10], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    cd graph4nlp\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "cd graph4nlp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ac9289e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavipariti/Documents/sem5_project/graph4nlp/graph4nlp\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f205a3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/vaishnavipariti/Documents/sem5_project/graph4nlp\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9630eddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/vaishnavipariti/Documents/sem5_project/graph4nlp'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c569b932",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
